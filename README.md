<h1 align="center">âš¡ NeuroHTTP â€” Fast AI-Native Web Server</h1>

<p align="center">
  <img src="https://img.shields.io/github/stars/okba14/NeuroHTTP?style=social" />
  <img src="https://img.shields.io/github/forks/okba14/NeuroHTTP?style=social" />
  <img src="https://img.shields.io/badge/language-C%20%2B%20ASM-blue?style=flat-square" />
  <img src="https://img.shields.io/badge/build-passing-brightgreen?style=flat-square" />
</p>

<p align="center"><em>High-performance, AI-native server built from scratch in C + Assembly â€” handles heavy AI payloads with minimal latency.</em></p>

---

# ğŸš€ Quick Start
## 1ï¸âƒ£ AI Provider Setup (Optional)

NeuroHTTP is provider-agnostic and does not require a specific AI vendor.

You may run the server using any OpenAI-compatible API, GROQ, or even a local AI model.

If your setup requires an API key, export it as an environment variable:

```bash
export OPENAI_API_KEY="gsk_XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"
```
## 2ï¸âƒ£ Install Dependencies

On Debian / Ubuntu / Kali:

```bash
sudo apt-get update
sudo apt-get install -y libcurl4-openssl-dev build-essential
```

## 3ï¸âƒ£ Clone the Repository & Build the Server

```bash
git clone https://github.com/okba14/NeuroHTTP.git
cd NeuroHTTP
make rebuild
```
The make rebuild command compiles the server from scratch.

## 4ï¸âƒ£ Run the Server

```bash
./bin/aionic
```
The server will run on port 8080 by default.
Logs are displayed in the same terminal.

## 5ï¸âƒ£ Send a Test Request (curl)

Open a second terminal and send a POST request:

```bash
curl -X POST http://localhost:8080/v1/chat \
-H "Content-Type: application/json" \
-d '{"prompt": "Hello."}'
```

## 6ï¸âƒ£ Example Response

```bash
{
  "response": "Hello! AI server received your prompt."
}
```
Users can now send any prompt to the AI server.

<!-- Professional Screenshots Layout (smaller images) -->
<div style="display: flex; flex-wrap: wrap; gap: 20px; justify-content: center;">

  <div style="flex: 1 1 150px; max-width: 200px; text-align: center;">
    <img src="videos/1.png" alt="Example Request" style="width: 100%; border: 1px solid #ccc; border-radius: 8px;">
    <p style="font-size: 0.85em; color: #555; margin-top: 5px;">
      Example of sending a POST request to the server.
    </p>
  </div>

  <div style="flex: 1 1 150px; max-width: 200px; text-align: center;">
    <img src="videos/2.png" alt="Example Response" style="width: 100%; border: 1px solid #ccc; border-radius: 8px;">
    <p style="font-size: 0.85em; color: #555; margin-top: 5px;">
      Server response displayed in terminal.
    </p>
  </div>

  <div style="flex: 1 1 150px; max-width: 200px; text-align: center;">
    <img src="videos/3.png" alt="Full Conversation" style="width: 100%; border: 1px solid #ccc; border-radius: 8px;">
    <p style="font-size: 0.85em; color: #555; margin-top: 5px;">
      Full AI conversation example in terminal.
    </p>
  </div>

</div>

 

# ğŸ”§ Important Notes

* Make sure the OPENAI_API_KEY environment variable is set before starting the server.
* To change the port or server options, edit include/config.h.
* The server uses libcurl to communicate with the AI backend.
---

## Benchmark Comparison

For detailed benchmark results comparing NeuroHTTP and NGINX, see [benchmark.md](benchmark.md)

## ğŸ§© Visual Benchmark Evidence

Below are the live screenshots from the actual benchmark runs.

### ğŸ”¹ NeuroHTTP â€” 40,000 Connections
![NeuroHTTP 40K Benchmark](videos/neurohttp_2.png)


### ğŸ”¹ NGINX â€” 40,000 Connections
![NGINX 40K Benchmark](videos/nginx_2.png)

# ğŸ§ª Performance Highlights

Server	Conns	Requests/sec	Avg Latency	Transfer/sec
NGINX 1.29.3	10k	8,148	114ms	1.2 MB/s
NeuroHTTP	10k	2,593	57ms	7.9 MB/s

ğŸ’¡ **Insight**  
## NeuroHTTP handles heavier, AI-rich payloads with lower latency and higher throughput per connection.

---

## ğŸŒŸ Why Star?

- Low latency, high throughput
- Compact C + Assembly core
- Open-source & extensible

If you love high-performance AI servers, consider giving the project a â­ and sharing it with others.

---

Â© 2025 GUIAR OQBA  
Licensed under the **MIT License**.

---

## â­ Support the Project

<p align="center">
  <a href="https://github.com/okba14/NeuroHTTP/stargazers">
    <img src="https://img.shields.io/github/stars/okba14/NeuroHTTP?style=for-the-badge&logo=github" alt="GitHub Stars"/>
  </a>
  <a href="https://github.com/okba14/NeuroHTTP/forks">
    <img src="https://img.shields.io/github/forks/okba14/NeuroHTTP?style=for-the-badge&logo=github" alt="GitHub Forks"/>
  </a>
  <a href="https://github.com/okba14">
    <img src="https://img.shields.io/badge/Follow-GUIAR%20OQBA-black?style=for-the-badge&logo=github" alt="Follow Developer"/>
  </a>
  <a href="https://github.com/okba14/NeuroHTTP/discussions">
    <img src="https://img.shields.io/badge/Join-Community-blueviolet?style=for-the-badge&logo=github" alt="Community"/>
  </a>
</p>

<p align="center">
  If you believe in the vision of a <strong>fast, AI-native web layer</strong>,  
  your support helps <strong>NeuroHTTP</strong> evolve. ğŸš€
</p>

---

## ğŸ§¬ Author

**ğŸ‘¨â€ğŸ’» GUIAR OQBA** ğŸ‡©ğŸ‡¿  
Creator of **NeuroHTTP** â€” focused on **low-level performance**, **AI infrastructure**, and **modern web systems**.

> _â€œBuilding the next generation of AI-native infrastructure â€” from El Kantara, Algeria.â€_
